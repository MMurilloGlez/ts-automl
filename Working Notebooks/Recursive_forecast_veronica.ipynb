{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vpinilla\\AppData\\Local\\Continuum\\miniconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\vpinilla\\AppData\\Local\\Continuum\\miniconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.JPIJNSWNNAN3CE6LLI5FWSPHUT2VXMTH.gfortran-win_amd64.dll\n",
      "C:\\Users\\vpinilla\\AppData\\Local\\Continuum\\miniconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\vpinilla\\AppData\\Local\\Continuum\\miniconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "C:\\Users\\vpinilla\\AppData\\Local\\Continuum\\miniconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pioç\n",
    "from statsmodels.tsa.stattools import pacf\n",
    "from sklearn.base import TransformerMixin\n",
    "from skits.preprocessing import HorizonTransformer\n",
    "import datetime\n",
    "from sktime.datasets import load_airline\n",
    "from sktime.forecasting.compose import ReducedForecaster\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split, SlidingWindowSplitter\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df = pd.DataFrame(load_airline())\n",
    "target = 'Number of airline passengers'\n",
    "df.index = pd.date_range(start='2021-02-05 14:07:33.511000+00:00', periods=len(df), \n",
    "                         freq='15min').tz_convert('Europe/Berlin')[:len(df)]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = 50\n",
    "window_length = 100\n",
    "rolling_window = [5,10,20]\n",
    "horizon = 1\n",
    "step = 1\n",
    "freq = '1T'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INSTALACIONES [kWh]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-02-05 15:07:33.511000+01:00</th>\n",
       "      <td>429.136414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-05 15:08:33.511000+01:00</th>\n",
       "      <td>441.115204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-05 15:09:33.511000+01:00</th>\n",
       "      <td>437.226990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-05 15:10:33.511000+01:00</th>\n",
       "      <td>415.408021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-05 15:11:33.511000+01:00</th>\n",
       "      <td>432.827713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-08 09:42:33.511000+01:00</th>\n",
       "      <td>455.932999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-08 09:43:33.511000+01:00</th>\n",
       "      <td>481.249069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-08 09:44:33.511000+01:00</th>\n",
       "      <td>462.117005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-08 09:45:33.511000+01:00</th>\n",
       "      <td>478.533279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-08 09:46:33.511000+01:00</th>\n",
       "      <td>371.435425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  INSTALACIONES [kWh]\n",
       "2000-02-05 15:07:33.511000+01:00           429.136414\n",
       "2000-02-05 15:08:33.511000+01:00           441.115204\n",
       "2000-02-05 15:09:33.511000+01:00           437.226990\n",
       "2000-02-05 15:10:33.511000+01:00           415.408021\n",
       "2000-02-05 15:11:33.511000+01:00           432.827713\n",
       "...                                               ...\n",
       "2000-02-08 09:42:33.511000+01:00           455.932999\n",
       "2000-02-08 09:43:33.511000+01:00           481.249069\n",
       "2000-02-08 09:44:33.511000+01:00           462.117005\n",
       "2000-02-08 09:45:33.511000+01:00           478.533279\n",
       "2000-02-08 09:46:33.511000+01:00           371.435425\n",
       "\n",
       "[4000 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Seat.csv')\n",
    "# df = df.drop([5441,5445,50241,50535,50926,51490,52196,52418,54124,58615,58628,58676,59132,60029,60693,64036,65419])\n",
    "df.index = pd.date_range(start='2000-02-05 14:07:33.511000+00:00', periods=len(df), \n",
    "                         freq=freq).tz_convert('Europe/Berlin')\n",
    "df = df.iloc[:4000,[10]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3950 50\n"
     ]
    }
   ],
   "source": [
    "y_train, y_test = train_test_split(df, test_size=points, shuffle=False)\n",
    "print(y_train.shape[0], y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create train features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract_sample_features import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_features(X, window_length = 5, features = [], rolling_window = [2]):\n",
    "    lags_X = lags_sample(X, window_length=window_length, step=1)\n",
    "    df = lags_X.copy()\n",
    "    for f in features:\n",
    "        if rolling_window:\n",
    "            for rol in rolling_window:\n",
    "                aux = switch_sample_features(f, X, lags_X, rol)\n",
    "                df = pd.concat([df, aux], axis = 1).dropna()\n",
    "        else:\n",
    "            aux = switch_sample_features(f, X, lags_X, [])\n",
    "            df = pd.concat([df, aux], axis = 1).dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_sample_features(value, X, lags_X, rolling_window):\n",
    "    return { \n",
    "        'mean': lambda : mean_sample(lags_X, rolling_window),\n",
    "        'std': lambda : std_sample(lags_X, rolling_window),\n",
    "        'max': lambda : max_sample(lags_X, rolling_window),\n",
    "        'min': lambda : min_sample(lags_X, rolling_window),\n",
    "        'quantile': lambda : quantile_sample(lags_X, rolling_window),\n",
    "        'iqr': lambda : iqr_sample(lags_X, rolling_window),\n",
    "        'entropy': lambda : entropy_sample(lags_X, rolling_window),\n",
    "        'trimmean': lambda : trimmean_sample(lags_X, rolling_window),\n",
    "        'variation': lambda : variation_sample(lags_X, rolling_window),\n",
    "        'hmean': lambda : hmean_sample(lags_X, rolling_window),\n",
    "        'gmean': lambda : gmean_sample(lags_X, rolling_window),\n",
    "        'mad': lambda : mad_sample(lags_X, rolling_window),\n",
    "#         'gstd': lambda : gstd_sample(lags_X, rolling_window),\n",
    "        'tvar': lambda : tvar_sample(lags_X, rolling_window),\n",
    "        'kurtosis': lambda : kurtosis_sample(lags_X, rolling_window),\n",
    "        'sem': lambda : sem_sample(lags_X, rolling_window),\n",
    "        'wav': lambda : wav_sample(lags_X, rolling_window),\n",
    "        #-----------------------------------------\n",
    "        'minute': lambda : minute_sample(X),\n",
    "        'hour': lambda : hour_sample(X),\n",
    "        'dayofweek': lambda : dayofweek_sample(X),\n",
    "        'day': lambda : day_sample(X),\n",
    "        'month': lambda : month_sample(X),\n",
    "        'quarter': lambda : quarter_sample(X),\n",
    "        'weekofyear': lambda : weekofyear_sample(X),\n",
    "        'weekend': lambda : weekend_sample(X)\n",
    "        \n",
    "    }.get(value)()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_horizon(df, horizon):\n",
    "    y = df.copy()\n",
    "    ht = HorizonTransformer(horizon = horizon+1)\n",
    "    y_horizon = ht.fit_transform(y.iloc[:,0]) #Los horizon ultimos valores son nan ya que no se puede crear un horizonte completo para ellos\n",
    "    y_horizon = pd.DataFrame(y_horizon[:-horizon, :], index = y.index[horizon:])\n",
    "    name = 't+'+str(horizon)\n",
    "    y_horizon = pd.DataFrame({name : y_horizon.iloc[:, -1]})\n",
    "    \n",
    "    return y_horizon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(X, y, num_features):\n",
    "    clf = lgb.LGBMRegressor(n_estimators=40).fit(X, y)\n",
    "    best_indx_col = clf.feature_importances_.argsort()[-num_features:]\n",
    "    best_features = list(X_train.columns[best_indx_col])\n",
    "    return order_by_other_list(X_train.columns, best_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_by_other_list(list_order, list_tobe_order):\n",
    "    d = {k:v for v,k in enumerate(list_order)}\n",
    "    list_tobe_order.sort(key=d.get)\n",
    "    return list_tobe_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract_features import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_features(value, lags_data, date, rolling_window, num):\n",
    "    return {\n",
    "        'lag': lambda : lag_feature(lags_data, num),\n",
    "        #--------------------------------------------------------------\n",
    "        'mean': lambda : mean_feature(lags_data, rolling_window, num),\n",
    "        'std': lambda : std_feature(lags_data, rolling_window, num),\n",
    "        'max': lambda : max_feature(lags_data, rolling_window, num),\n",
    "        'min': lambda : min_feature(lags_data, rolling_window, num),\n",
    "        'quantile': lambda : quantile_feature(lags_data, rolling_window, num),\n",
    "        'iqr': lambda : iqr_feature(lags_data, rolling_window, num),\n",
    "        'entropy': lambda : entropy_feature(lags_data, rolling_window, num),\n",
    "        'trimmean': lambda : trimmean_feature(lags_data, rolling_window, num),\n",
    "        'variation': lambda : variation_feature(lags_data, rolling_window, num),\n",
    "        'hmean': lambda : hmean_feature(lags_data, rolling_window, num),\n",
    "        'gmean': lambda : gmean_feature(lags_data, rolling_window, num),\n",
    "        'mad': lambda : mad_feature(lags_data, rolling_window, num),\n",
    "#         'gstd': lambda : gstd_feature(lags_data, rolling_window, num),\n",
    "        'tvar': lambda : tvar_feature(lags_data, rolling_window, num),\n",
    "        'kurtosis': lambda : kurtosis_feature(lags_data, rolling_window, num),\n",
    "        'sem': lambda : sem_feature(lags_data, rolling_window, num),\n",
    "        'wav': lambda : wav_feature(lags_data, rolling_window, num),\n",
    "        #--------------------------------------------------------------\n",
    "        'minute': lambda : minute_feature(date, num),\n",
    "        'hour': lambda : hour_feature(date, num),\n",
    "        'dayofweek': lambda : dayofweek_feature(date, num),\n",
    "        'day': lambda : day_feature(date, num),\n",
    "        'month': lambda : month_feature(date, num),\n",
    "        'quarter': lambda : quarter_feature(date, num),\n",
    "        'weekofyear': lambda : weekofyear_feature(date, num),\n",
    "        'weekend': lambda : weekend_feature(date, num)\n",
    "    }.get(value)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(feature_names, lags_data, date):\n",
    "    features = []\n",
    "    for f in feature_names:\n",
    "        ftype, info = f.split('_',1)\n",
    "        if '_' in info:\n",
    "            rolling_window, num = info.split('_')\n",
    "            num = int(num)\n",
    "            rolling_window = int(rolling_window)\n",
    "        else:\n",
    "            num = int(info)\n",
    "            rolling_window = None\n",
    "        features.append(switch_features(ftype, lags_data, date, rolling_window, num))\n",
    "                                \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_optimization(value, regressor):\n",
    "    return {\n",
    "        'tpe': lambda : tpe_optimization(),\n",
    "        'pso': lambda : pso_optimization(),\n",
    "    }.get(value)()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_forecast(y, model, window_length, feature_names, rolling_window, n_steps):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    y: pd.Series holding the input time-series to forecast\n",
    "    model: pre-trained machine learning model\n",
    "    lags: list of lags used for training the model\n",
    "    n_steps: number of time periods in the forecasting horizon\n",
    "    step: forecasting time period\n",
    "   \n",
    "    Returns\n",
    "    -------\n",
    "    fcast_values: pd.Series with forecasted values\n",
    "    \"\"\"\n",
    "   \n",
    "    # get the dates to forecast\n",
    "    last_date = y.index[-1] + datetime.timedelta(minutes=15)\n",
    "    target_range = pd.date_range(last_date, periods=n_steps, freq=freq)\n",
    "    target_value = np.arange(n_steps)\n",
    "    max_rol = max(rolling_window, default=1)\n",
    "    lags = list(y.iloc[-(window_length+(max_rol-1)):,0].values)\n",
    "    ####\n",
    "    \n",
    "    \n",
    "    for i in range(n_steps):\n",
    "        train = create_features(feature_names, lags, target_range[i])\n",
    "        new_value = model.predict(pd.DataFrame(train).transpose())\n",
    "        target_value[i] = new_value[0]\n",
    "        lags.pop(0)\n",
    "        lags.append(new_value[0])\n",
    "           \n",
    "    return target_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = ['mean', 'std', 'max', 'min', 'quantile', 'iqr', 'entropy', 'trimmean', 'variation', 'hmean', 'gmean', 'mad', 'tvar',\n",
    "#             'kurtosis', 'sem', 'minute', 'hour', 'dayofweek', 'day', 'month', 'quarter', 'weekofyear', 'weekend']\n",
    "features = ['mean', 'std', 'max', 'min', 'minute']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag_100</th>\n",
       "      <th>lag_99</th>\n",
       "      <th>lag_98</th>\n",
       "      <th>lag_97</th>\n",
       "      <th>lag_96</th>\n",
       "      <th>lag_95</th>\n",
       "      <th>lag_94</th>\n",
       "      <th>lag_93</th>\n",
       "      <th>lag_92</th>\n",
       "      <th>lag_91</th>\n",
       "      <th>...</th>\n",
       "      <th>minute_51</th>\n",
       "      <th>minute_52</th>\n",
       "      <th>minute_53</th>\n",
       "      <th>minute_54</th>\n",
       "      <th>minute_55</th>\n",
       "      <th>minute_56</th>\n",
       "      <th>minute_57</th>\n",
       "      <th>minute_58</th>\n",
       "      <th>minute_59</th>\n",
       "      <th>minute_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-02-05 17:06:33.511000+01:00</th>\n",
       "      <td>441.426468</td>\n",
       "      <td>420.912125</td>\n",
       "      <td>363.387573</td>\n",
       "      <td>388.791611</td>\n",
       "      <td>404.939103</td>\n",
       "      <td>423.678970</td>\n",
       "      <td>429.227005</td>\n",
       "      <td>415.894593</td>\n",
       "      <td>426.114227</td>\n",
       "      <td>425.496506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-05 17:07:33.511000+01:00</th>\n",
       "      <td>420.912125</td>\n",
       "      <td>363.387573</td>\n",
       "      <td>388.791611</td>\n",
       "      <td>404.939103</td>\n",
       "      <td>423.678970</td>\n",
       "      <td>429.227005</td>\n",
       "      <td>415.894593</td>\n",
       "      <td>426.114227</td>\n",
       "      <td>425.496506</td>\n",
       "      <td>427.149979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-05 17:08:33.511000+01:00</th>\n",
       "      <td>363.387573</td>\n",
       "      <td>388.791611</td>\n",
       "      <td>404.939103</td>\n",
       "      <td>423.678970</td>\n",
       "      <td>429.227005</td>\n",
       "      <td>415.894593</td>\n",
       "      <td>426.114227</td>\n",
       "      <td>425.496506</td>\n",
       "      <td>427.149979</td>\n",
       "      <td>413.574082</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-05 17:09:33.511000+01:00</th>\n",
       "      <td>388.791611</td>\n",
       "      <td>404.939103</td>\n",
       "      <td>423.678970</td>\n",
       "      <td>429.227005</td>\n",
       "      <td>415.894593</td>\n",
       "      <td>426.114227</td>\n",
       "      <td>425.496506</td>\n",
       "      <td>427.149979</td>\n",
       "      <td>413.574082</td>\n",
       "      <td>337.172134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-05 17:10:33.511000+01:00</th>\n",
       "      <td>404.939103</td>\n",
       "      <td>423.678970</td>\n",
       "      <td>429.227005</td>\n",
       "      <td>415.894593</td>\n",
       "      <td>426.114227</td>\n",
       "      <td>425.496506</td>\n",
       "      <td>427.149979</td>\n",
       "      <td>413.574082</td>\n",
       "      <td>337.172134</td>\n",
       "      <td>413.618301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1480 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     lag_100      lag_99      lag_98  \\\n",
       "2000-02-05 17:06:33.511000+01:00  441.426468  420.912125  363.387573   \n",
       "2000-02-05 17:07:33.511000+01:00  420.912125  363.387573  388.791611   \n",
       "2000-02-05 17:08:33.511000+01:00  363.387573  388.791611  404.939103   \n",
       "2000-02-05 17:09:33.511000+01:00  388.791611  404.939103  423.678970   \n",
       "2000-02-05 17:10:33.511000+01:00  404.939103  423.678970  429.227005   \n",
       "\n",
       "                                      lag_97      lag_96      lag_95  \\\n",
       "2000-02-05 17:06:33.511000+01:00  388.791611  404.939103  423.678970   \n",
       "2000-02-05 17:07:33.511000+01:00  404.939103  423.678970  429.227005   \n",
       "2000-02-05 17:08:33.511000+01:00  423.678970  429.227005  415.894593   \n",
       "2000-02-05 17:09:33.511000+01:00  429.227005  415.894593  426.114227   \n",
       "2000-02-05 17:10:33.511000+01:00  415.894593  426.114227  425.496506   \n",
       "\n",
       "                                      lag_94      lag_93      lag_92  \\\n",
       "2000-02-05 17:06:33.511000+01:00  429.227005  415.894593  426.114227   \n",
       "2000-02-05 17:07:33.511000+01:00  415.894593  426.114227  425.496506   \n",
       "2000-02-05 17:08:33.511000+01:00  426.114227  425.496506  427.149979   \n",
       "2000-02-05 17:09:33.511000+01:00  425.496506  427.149979  413.574082   \n",
       "2000-02-05 17:10:33.511000+01:00  427.149979  413.574082  337.172134   \n",
       "\n",
       "                                      lag_91  ...  minute_51  minute_52  \\\n",
       "2000-02-05 17:06:33.511000+01:00  425.496506  ...        0.0        0.0   \n",
       "2000-02-05 17:07:33.511000+01:00  427.149979  ...        0.0        0.0   \n",
       "2000-02-05 17:08:33.511000+01:00  413.574082  ...        0.0        0.0   \n",
       "2000-02-05 17:09:33.511000+01:00  337.172134  ...        0.0        0.0   \n",
       "2000-02-05 17:10:33.511000+01:00  413.618301  ...        0.0        0.0   \n",
       "\n",
       "                                  minute_53  minute_54  minute_55  minute_56  \\\n",
       "2000-02-05 17:06:33.511000+01:00        0.0        0.0        0.0        0.0   \n",
       "2000-02-05 17:07:33.511000+01:00        0.0        0.0        0.0        0.0   \n",
       "2000-02-05 17:08:33.511000+01:00        0.0        0.0        0.0        0.0   \n",
       "2000-02-05 17:09:33.511000+01:00        0.0        0.0        0.0        0.0   \n",
       "2000-02-05 17:10:33.511000+01:00        0.0        0.0        0.0        0.0   \n",
       "\n",
       "                                  minute_57  minute_58  minute_59  minute_60  \n",
       "2000-02-05 17:06:33.511000+01:00        0.0        0.0        0.0        0.0  \n",
       "2000-02-05 17:07:33.511000+01:00        0.0        0.0        0.0        0.0  \n",
       "2000-02-05 17:08:33.511000+01:00        0.0        0.0        0.0        0.0  \n",
       "2000-02-05 17:09:33.511000+01:00        0.0        0.0        0.0        0.0  \n",
       "2000-02-05 17:10:33.511000+01:00        0.0        0.0        0.0        0.0  \n",
       "\n",
       "[5 rows x 1480 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = create_sample_features(y_train, window_length=window_length, features=features, rolling_window=rolling_window)\n",
    "y_horizon = create_horizon(y_train, horizon)\n",
    "y_horizon = y_horizon.loc[X_train.index[0]:,:]\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**De 15 lags seleccionamos los 5 primeros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feat = 100\n",
    "best_features = feature_selection(X_train, y_horizon.values.ravel(), selected_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selec = X_train.loc[:, best_features]\n",
    "X_train_selec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = lgb.LGBMRegressor()\n",
    "regressor.fit(X_train_selec, y_horizon.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_manual = recursive_forecast(y_train, regressor, window_length=window_length, feature_names=best_features,\n",
    "                                rolling_window=rolling_window, n_steps=points)\n",
    "print('RMSE loss: %.2f' % (mean_squared_error(y_test, pred_manual, squared=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "# fig.add_trace(\n",
    "#     go.Scatter(x=list(y_train.index), y=list(y_train.iloc[:,0]),mode='lines+markers',name = \"Train\"))\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=list(y_test.index), y=list(y_test.iloc[:,0]), mode='lines+markers', name = \"Test\"))\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=list(y_test.index), y=list(pred_manual), line=go.scatter.Line(color=\"green\"), name = \"Pred\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_well(y, X, window_length, feature_names, n_steps, rolling_window=[]):   \n",
    "    target_range = pd.date_range(X.index[0], periods=n_steps, freq=freq)\n",
    "    names = [i.split('_')[0] for i in feature_names]\n",
    "    max_rol = max(rolling_window, default=1)\n",
    "    lags = list(y.iloc[:window_length+max_rol-1,0])\n",
    "    for i in range(n_steps):\n",
    "        train = create_features(feature_names, lags, target_range[i])\n",
    "        train = [round(num, 2) for num in train]\n",
    "        r = [round(num, 2) for num in list(X.iloc[i,:])]\n",
    "        if not r == train:\n",
    "            print('Not all features have been created correctly')\n",
    "            return\n",
    "        lags.pop(0)\n",
    "        lags.append(float(y.iloc[window_length+max_rol-1+i,:]))\n",
    "    print('All features have been created correctly')\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_well(y_train, X_train_selec, window_length, best_features ,points, rolling_window)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
